{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d2fc65-6d57-4a8f-8bb5-618e43b3b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 23:12:55.280495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.308164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.308367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.309384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-12 23:12:55.310727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.310942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.311082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.724758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.724944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.725088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 23:12:55.725205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4362 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/ramizouari/anaconda3/envs/tensorflow_2_9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import larq as lq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from binaryflow import quantizers\n",
    "from binaryflow.layers import ABCNet,XnorNet,BinaryNet\n",
    "from binaryflow.block import BiRealNet\n",
    "from binaryflow.layers.normalization import *\n",
    "from contextlib import redirect_stdout\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39d36c-6223-453d-9d5a-09a03b96dabe",
   "metadata": {},
   "source": [
    "## 1. Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2edca9f-b476-4db3-8129-4cb9b1961aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import scipy.io\n",
    "\n",
    "class AudioMNISTRow():\n",
    "    def __init__(self,data,size:int,rate:int,label,person:str):\n",
    "        self.data=data\n",
    "        self.size=size\n",
    "        self.label=label\n",
    "        self.person=person\n",
    "        self.rate=rate\n",
    "    def __repr__(self)->str:\n",
    "        return f\"{self.person}'s pronunciation for digit {self.label}: {self.data}\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def toDataFrame(rows):\n",
    "        return pd.DataFrame([[row.person,self.rate,row.size,row.data,row.label] for row in rows],columns=[\"Person\",\"Rate\",\"Size\",\"Data\",\"Label\"])\n",
    "    \n",
    "\n",
    "def load_audio_mnist(path:str):\n",
    "    U=[]\n",
    "    for fileName in os.listdir(path):\n",
    "        match=re.match(R\"([0-9])_(\\w+)_[0-9]+\\.wav\",fileName)\n",
    "        if match:\n",
    "            rate,data=scipy.io.wavfile.read(f\"{path}/{fileName}\")\n",
    "            size=len(data)\n",
    "            U.append(AudioMNISTRow(data=data,rate=rate,size=size,label=int(match.group(1)[0]),person=match.group(2)))\n",
    "    return U\n",
    "\n",
    "\n",
    "class AudioMNIST(pd.DataFrame):\n",
    "    def __init__(self,rows):\n",
    "        super().__init__([[row.person,row.rate,row.size,pd.Series(row.data),row.label] for row in rows],columns=[\"Person\",\"Rate\",\"Size\",\"Data\",\"Label\"])\n",
    "        self.radius=self[\"Size\"].min()\n",
    "    \n",
    "    def augment(self):\n",
    "        U=[]\n",
    "        for i in range(self.shape[0]):\n",
    "            row=self.iloc[i]\n",
    "            j=i\n",
    "            while j+self.radius <= len(row[\"Data\"]):\n",
    "                U.append([row[\"Person\"],row[\"Rate\"],*row[\"Data\"][j:j+self.radius],row[\"Label\"]])\n",
    "                j+=1\n",
    "        \n",
    "        return pd.DataFrame(U,columns=[\"Person\",\"Rate\",*[f\"Timestamp {i}\" for i in range(self.radius)],\"Label\"])\n",
    "    def stochasticCrop(self,count,to_tensor=False,to_list=False,radius=None):\n",
    "        if radius is None:\n",
    "            radius=self.radius\n",
    "        U=[]\n",
    "        for i in range(self.shape[0]):\n",
    "            row=self.iloc[i]\n",
    "            if radius < row[\"Size\"]:\n",
    "                K=np.random.randint(0,row[\"Size\"]-radius+1,count)\n",
    "                for k in K:\n",
    "                    U.append([row[\"Person\"],row[\"Rate\"],*row[\"Data\"][k:k+radius],row[\"Label\"]])\n",
    "            else:\n",
    "                K=np.random.randint(0,radius-row[\"Size\"],count)\n",
    "                n=radius-row[\"Size\"]\n",
    "                for k in K:\n",
    "                    U.append([row[\"Person\"],row[\"Rate\"],*np.zeros(k),*row[\"Data\"],*np.zeros(n-k),row[\"Label\"]])\n",
    "        if to_list:\n",
    "            return U\n",
    "        elif to_tensor:\n",
    "            return tf.constant([V[2:-1] for V in U]),tf.constant([V[-1] for V in U])\n",
    "        else:\n",
    "            return pd.DataFrame(U,columns=[\"Person\",\"Rate\",*[f\"Timestamp {i}\" for i in range(radius)],\"Label\"])\n",
    "    def flatten(self):\n",
    "        L=[]\n",
    "        for i in range(self.shape[0]):\n",
    "            row=self.iloc[i]\n",
    "            for index,s in enumerate(row[\"Data\"]):\n",
    "                L.append([row[\"Person\"],row[\"Rate\"],row[\"Label\"],index,s])\n",
    "        return pd.DataFrame(L,columns=[\"Person\",\"Rate\",\"Label\",\"Timestamp\",\"Amplitude\"])\n",
    "        \n",
    "def joinSpectralDomain(X):\n",
    "    shape=X.shape+[1]\n",
    "    return tf.concat([tf.reshape(X,shape),tf.reshape(tf.signal.dct(X),shape)],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0509600e-2e11-4588-90fd-df9c15066c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "U=load_audio_mnist(\"dataset/audio-mnist/recordings\")\n",
    "U=AudioMNIST(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86063fc5-b121-4167-b4f7-31f254aa3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "radius=2000\n",
    "X,y=U.stochasticCrop(10,to_tensor=True,radius=radius)\n",
    "X=tf.reshape(tf.signal.dct(X),X.shape+[1])\n",
    "X_train,X_test,y_train,y_test= train_test_split(X.numpy().astype(dtype=float),y.numpy(),train_size=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "419deb1c-a1d2-48b0-bf32-707e20e8fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_kwargs=dict(kernel_quantizer=\"ste_sign\",input_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\")\n",
    "abc_kwargs=dict(kernel_quantizers=quantizers.ShiftedSteSign,input_quantizers=quantizers.ShiftedSteSign,kernel_constraint=\"weight_clip\",\n",
    "               kernel_estimators=3)\n",
    "Dense=BinaryNet.QuantDense\n",
    "Conv1D=BinaryNet.QuantConv1D\n",
    "x=tf.keras.layers.Input(shape=(radius,1))\n",
    "s=tf.keras.layers.GaussianNoise(stddev=15)(x)\n",
    "s=s/tf.math.reduce_max(x,axis=-2,keepdims=True)\n",
    "s=tf.keras.layers.BatchNormalization(momentum=0.999,scale=False)(s)\n",
    "x1=Conv1D(128,3,activation=\"tanh\",**bnn_kwargs,padding=\"same\",name=\"hola\")(s)\n",
    "x1=tf.keras.layers.MaxPool1D(3,strides=2)(x1)\n",
    "x2=tf.keras.layers.BatchNormalization(momentum=0.999,scale=False)(x1)           \n",
    "x2=Conv1D(128,9,activation=\"relu\",**bnn_kwargs,padding=\"same\")(x1)+x1\n",
    "x2=tf.keras.layers.MaxPool1D(3,strides=2)(x2)\n",
    "x2=tf.keras.layers.BatchNormalization(momentum=0.999,scale=False)(x2)            \n",
    "x3=Conv1D(128,19,activation=\"relu\",**bnn_kwargs,padding=\"same\")(x2)+x2\n",
    "x3=tf.keras.layers.MaxPool1D(3,strides=2)(x3)\n",
    "x3=tf.keras.layers.Flatten()(x3)\n",
    "x3=tf.keras.layers.BatchNormalization(momentum=0.999,scale=False)(x3)\n",
    "x4=Dense(256,activation=\"relu\",**bnn_kwargs,use_bias=False)(x3)\n",
    "x4=tf.keras.layers.BatchNormalization(momentum=0.999,scale=False)(x4)\n",
    "y=tf.keras.layers.Dense(10)(x4)\n",
    "y=tf.keras.layers.Activation(\"softmax\")(y)\n",
    "model=tf.keras.Model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1cf14d2-c86f-4fd9-acee-b11cc0c5da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramizouari/anaconda3/envs/tensorflow_2_9/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "176/176 [==============================] - 21s 112ms/step - loss: 0.9718 - accuracy: 0.6846 - val_loss: 468.6893 - val_accuracy: 0.0925\n",
      "Epoch 2/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.6908 - accuracy: 0.7695 - val_loss: 168.0598 - val_accuracy: 0.0925\n",
      "Epoch 3/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.5931 - accuracy: 0.7998 - val_loss: 154.5296 - val_accuracy: 0.0925\n",
      "Epoch 4/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.4652 - accuracy: 0.8428 - val_loss: 222.9056 - val_accuracy: 0.0925\n",
      "Epoch 5/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.4471 - accuracy: 0.8482 - val_loss: 10.7429 - val_accuracy: 0.1113\n",
      "Epoch 6/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.3899 - accuracy: 0.8658 - val_loss: 60.1891 - val_accuracy: 0.1008\n",
      "Epoch 7/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.3351 - accuracy: 0.8822 - val_loss: 6.5632 - val_accuracy: 0.0993\n",
      "Epoch 8/90\n",
      "176/176 [==============================] - 19s 111ms/step - loss: 0.3526 - accuracy: 0.8807 - val_loss: 23.9499 - val_accuracy: 0.1103\n",
      "Epoch 9/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.2946 - accuracy: 0.8999 - val_loss: 3.8463 - val_accuracy: 0.2291\n",
      "Epoch 10/90\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.2322 - accuracy: 0.9215 - val_loss: 4.9642 - val_accuracy: 0.1328\n",
      "Epoch 11/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.2207 - accuracy: 0.9231 - val_loss: 5.7723 - val_accuracy: 0.1699\n",
      "Epoch 12/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.2417 - accuracy: 0.9128 - val_loss: 3.5367 - val_accuracy: 0.1824\n",
      "Epoch 13/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.1900 - accuracy: 0.9328 - val_loss: 3.9406 - val_accuracy: 0.1867\n",
      "Epoch 14/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.1694 - accuracy: 0.9426 - val_loss: 3.5657 - val_accuracy: 0.2596\n",
      "Epoch 15/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1637 - accuracy: 0.9421 - val_loss: 3.4325 - val_accuracy: 0.2133\n",
      "Epoch 16/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.1692 - accuracy: 0.9404 - val_loss: 3.4666 - val_accuracy: 0.2868\n",
      "Epoch 17/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.1775 - accuracy: 0.9392 - val_loss: 4.1548 - val_accuracy: 0.1952\n",
      "Epoch 18/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1503 - accuracy: 0.9474 - val_loss: 3.8126 - val_accuracy: 0.3096\n",
      "Epoch 19/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.1594 - accuracy: 0.9453 - val_loss: 3.0584 - val_accuracy: 0.3983\n",
      "Epoch 20/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1527 - accuracy: 0.9462 - val_loss: 2.3143 - val_accuracy: 0.4063\n",
      "Epoch 21/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.1476 - accuracy: 0.9492 - val_loss: 2.1725 - val_accuracy: 0.4357\n",
      "Epoch 22/90\n",
      "176/176 [==============================] - 19s 111ms/step - loss: 0.1013 - accuracy: 0.9641 - val_loss: 2.9451 - val_accuracy: 0.3541\n",
      "Epoch 23/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1086 - accuracy: 0.9634 - val_loss: 2.8733 - val_accuracy: 0.4133\n",
      "Epoch 24/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1027 - accuracy: 0.9639 - val_loss: 3.6854 - val_accuracy: 0.3536\n",
      "Epoch 25/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1059 - accuracy: 0.9625 - val_loss: 3.7199 - val_accuracy: 0.2655\n",
      "Epoch 26/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1008 - accuracy: 0.9652 - val_loss: 3.2072 - val_accuracy: 0.4223\n",
      "Epoch 27/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0997 - accuracy: 0.9651 - val_loss: 2.5468 - val_accuracy: 0.4955\n",
      "Epoch 28/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.0993 - accuracy: 0.9652 - val_loss: 3.9234 - val_accuracy: 0.3164\n",
      "Epoch 29/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0957 - accuracy: 0.9677 - val_loss: 1.8684 - val_accuracy: 0.5556\n",
      "Epoch 30/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.1005 - accuracy: 0.9655 - val_loss: 4.0584 - val_accuracy: 0.3615\n",
      "Epoch 31/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0848 - accuracy: 0.9713 - val_loss: 2.0493 - val_accuracy: 0.5819\n",
      "Epoch 32/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0769 - accuracy: 0.9736 - val_loss: 2.6393 - val_accuracy: 0.5771\n",
      "Epoch 33/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0680 - accuracy: 0.9762 - val_loss: 2.5640 - val_accuracy: 0.4959\n",
      "Epoch 34/90\n",
      "176/176 [==============================] - 20s 114ms/step - loss: 0.0804 - accuracy: 0.9714 - val_loss: 2.4247 - val_accuracy: 0.5020\n",
      "Epoch 35/90\n",
      "176/176 [==============================] - 20s 114ms/step - loss: 0.0697 - accuracy: 0.9755 - val_loss: 2.4548 - val_accuracy: 0.5339\n",
      "Epoch 36/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0688 - accuracy: 0.9768 - val_loss: 2.8075 - val_accuracy: 0.4772\n",
      "Epoch 37/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0662 - accuracy: 0.9758 - val_loss: 2.1349 - val_accuracy: 0.5875\n",
      "Epoch 38/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0657 - accuracy: 0.9774 - val_loss: 2.9491 - val_accuracy: 0.4781\n",
      "Epoch 39/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0705 - accuracy: 0.9758 - val_loss: 2.6678 - val_accuracy: 0.5008\n",
      "Epoch 40/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0607 - accuracy: 0.9794 - val_loss: 1.6960 - val_accuracy: 0.5893\n",
      "Epoch 41/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0564 - accuracy: 0.9804 - val_loss: 3.5176 - val_accuracy: 0.5063\n",
      "Epoch 42/90\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 0.1109 - accuracy: 0.9628 - val_loss: 4.2896 - val_accuracy: 0.4027\n",
      "Epoch 43/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0616 - accuracy: 0.9788 - val_loss: 2.7950 - val_accuracy: 0.5460\n",
      "Epoch 44/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0656 - accuracy: 0.9783 - val_loss: 2.1252 - val_accuracy: 0.5995\n",
      "Epoch 45/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0521 - accuracy: 0.9826 - val_loss: 3.5624 - val_accuracy: 0.4177\n",
      "Epoch 46/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0535 - accuracy: 0.9822 - val_loss: 1.9821 - val_accuracy: 0.6936\n",
      "Epoch 47/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0948 - accuracy: 0.9689 - val_loss: 2.3479 - val_accuracy: 0.5845\n",
      "Epoch 48/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0632 - accuracy: 0.9782 - val_loss: 1.6718 - val_accuracy: 0.6524\n",
      "Epoch 49/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0523 - accuracy: 0.9822 - val_loss: 1.6844 - val_accuracy: 0.6292\n",
      "Epoch 50/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 3.4006 - val_accuracy: 0.4668\n",
      "Epoch 51/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 1.5128 - val_accuracy: 0.7428\n",
      "Epoch 52/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 2.1540 - val_accuracy: 0.6229\n",
      "Epoch 53/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0429 - accuracy: 0.9850 - val_loss: 4.5310 - val_accuracy: 0.4529\n",
      "Epoch 54/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0369 - accuracy: 0.9874 - val_loss: 2.4320 - val_accuracy: 0.6177\n",
      "Epoch 55/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0417 - accuracy: 0.9856 - val_loss: 2.7231 - val_accuracy: 0.4997\n",
      "Epoch 56/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.0437 - accuracy: 0.9845 - val_loss: 4.0440 - val_accuracy: 0.4301\n",
      "Epoch 57/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.0430 - accuracy: 0.9853 - val_loss: 4.2077 - val_accuracy: 0.3861\n",
      "Epoch 58/90\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 3.4573 - val_accuracy: 0.4909\n",
      "Epoch 59/90\n",
      "176/176 [==============================] - 18s 104ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 2.0720 - val_accuracy: 0.6552\n",
      "Epoch 60/90\n",
      "176/176 [==============================] - 19s 106ms/step - loss: 0.0343 - accuracy: 0.9877 - val_loss: 1.6580 - val_accuracy: 0.7348\n",
      "Epoch 61/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 2.1785 - val_accuracy: 0.6689\n",
      "Epoch 62/90\n",
      "176/176 [==============================] - 18s 104ms/step - loss: 0.0347 - accuracy: 0.9892 - val_loss: 3.7652 - val_accuracy: 0.5145\n",
      "Epoch 63/90\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 0.0437 - accuracy: 0.9856 - val_loss: 3.9560 - val_accuracy: 0.5204\n",
      "Epoch 64/90\n",
      "176/176 [==============================] - 20s 116ms/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 2.3943 - val_accuracy: 0.6224\n",
      "Epoch 65/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 3.4342 - val_accuracy: 0.5499\n",
      "Epoch 66/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 1.4865 - val_accuracy: 0.7229\n",
      "Epoch 67/90\n",
      "176/176 [==============================] - 19s 109ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 3.8398 - val_accuracy: 0.4800\n",
      "Epoch 68/90\n",
      "176/176 [==============================] - 20s 114ms/step - loss: 0.0313 - accuracy: 0.9893 - val_loss: 3.1225 - val_accuracy: 0.4579\n",
      "Epoch 69/90\n",
      "176/176 [==============================] - 20s 115ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 4.1660 - val_accuracy: 0.4691\n",
      "Epoch 70/90\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 1.7787 - val_accuracy: 0.6456\n",
      "Epoch 71/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0423 - accuracy: 0.9858 - val_loss: 1.9660 - val_accuracy: 0.6219\n",
      "Epoch 72/90\n",
      "176/176 [==============================] - 20s 112ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 2.8778 - val_accuracy: 0.6271\n",
      "Epoch 73/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0349 - accuracy: 0.9892 - val_loss: 3.8191 - val_accuracy: 0.4257\n",
      "Epoch 74/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 3.4999 - val_accuracy: 0.5653\n",
      "Epoch 75/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 1.8914 - val_accuracy: 0.6940\n",
      "Epoch 76/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 4.4823 - val_accuracy: 0.4531\n",
      "Epoch 77/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 2.7024 - val_accuracy: 0.5781\n",
      "Epoch 78/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0450 - accuracy: 0.9850 - val_loss: 7.5281 - val_accuracy: 0.3095\n",
      "Epoch 79/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0307 - accuracy: 0.9889 - val_loss: 3.2634 - val_accuracy: 0.5139\n",
      "Epoch 80/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 4.7630 - val_accuracy: 0.4297\n",
      "Epoch 81/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 2.0959 - val_accuracy: 0.6939\n",
      "Epoch 82/90\n",
      "176/176 [==============================] - 20s 111ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 2.5621 - val_accuracy: 0.5724\n",
      "Epoch 83/90\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 3.0577 - val_accuracy: 0.5055\n",
      "Epoch 84/90\n",
      "176/176 [==============================] - 20s 114ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 2.1341 - val_accuracy: 0.6888\n",
      "Epoch 85/90\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 1.5040 - val_accuracy: 0.7412\n",
      "Epoch 86/90\n",
      "176/176 [==============================] - 18s 105ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 1.0583 - val_accuracy: 0.8037\n",
      "Epoch 87/90\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 1.7891 - val_accuracy: 0.6791\n",
      "Epoch 88/90\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0338 - accuracy: 0.9888 - val_loss: 4.6159 - val_accuracy: 0.5231\n",
      "Epoch 89/90\n",
      "176/176 [==============================] - 18s 104ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 2.7111 - val_accuracy: 0.6437\n",
      "Epoch 90/90\n",
      "176/176 [==============================] - 19s 111ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 2.4370 - val_accuracy: 0.5943\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "tf.keras.optimizers.Adam(lr=0.01, decay=0.0001),\n",
    "loss=\"categorical_crossentropy\",\n",
    "metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "trained_model = model.fit(\n",
    "    X_train, \n",
    "    tf.one_hot(y_train,10),\n",
    "    batch_size=128, \n",
    "    epochs=90,\n",
    "    validation_data=(X_test,tf.one_hot(y_test,10)),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a979f4f-5127-4ea1-8dc9-a93096d43367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0597 - accuracy: 0.9801 - val_loss: 5.1658 - val_accuracy: 0.4187\n",
      "Epoch 2/30\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 6.9967 - val_accuracy: 0.3233\n",
      "Epoch 3/30\n",
      "176/176 [==============================] - 19s 106ms/step - loss: 0.0674 - accuracy: 0.9767 - val_loss: 3.3788 - val_accuracy: 0.5156\n",
      "Epoch 4/30\n",
      "176/176 [==============================] - 19s 106ms/step - loss: 0.0806 - accuracy: 0.9730 - val_loss: 2.6283 - val_accuracy: 0.4717\n",
      "Epoch 5/30\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 5.2961 - val_accuracy: 0.3339\n",
      "Epoch 6/30\n",
      "176/176 [==============================] - 19s 106ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 4.6750 - val_accuracy: 0.4173\n",
      "Epoch 7/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 5.2577 - val_accuracy: 0.3919\n",
      "Epoch 8/30\n",
      "176/176 [==============================] - 20s 113ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 4.4744 - val_accuracy: 0.3985\n",
      "Epoch 9/30\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 3.6160 - val_accuracy: 0.4644\n",
      "Epoch 10/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0398 - accuracy: 0.9864 - val_loss: 1.4952 - val_accuracy: 0.6856\n",
      "Epoch 11/30\n",
      "176/176 [==============================] - 19s 108ms/step - loss: 0.0390 - accuracy: 0.9870 - val_loss: 1.8591 - val_accuracy: 0.5928\n",
      "Epoch 12/30\n",
      "176/176 [==============================] - 18s 103ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 3.0338 - val_accuracy: 0.5279\n",
      "Epoch 13/30\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 3.7684 - val_accuracy: 0.4588\n",
      "Epoch 14/30\n",
      "176/176 [==============================] - 18s 104ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 4.6791 - val_accuracy: 0.4195\n",
      "Epoch 15/30\n",
      "176/176 [==============================] - 18s 103ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 5.0895 - val_accuracy: 0.4092\n",
      "Epoch 16/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 2.5828 - val_accuracy: 0.5860\n",
      "Epoch 17/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 3.7410 - val_accuracy: 0.5064\n",
      "Epoch 18/30\n",
      "176/176 [==============================] - 18s 103ms/step - loss: 0.0548 - accuracy: 0.9817 - val_loss: 7.1361 - val_accuracy: 0.3321\n",
      "Epoch 19/30\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 3.8074 - val_accuracy: 0.4483\n",
      "Epoch 20/30\n",
      "176/176 [==============================] - 19s 110ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 3.1695 - val_accuracy: 0.5637\n",
      "Epoch 21/30\n",
      "176/176 [==============================] - 18s 103ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 3.4316 - val_accuracy: 0.5192\n",
      "Epoch 22/30\n",
      "176/176 [==============================] - 19s 111ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 1.8248 - val_accuracy: 0.6652\n",
      "Epoch 23/30\n",
      "176/176 [==============================] - 19s 107ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 13.9959 - val_accuracy: 0.2895\n",
      "Epoch 24/30\n",
      "176/176 [==============================] - 19s 106ms/step - loss: 0.1581 - accuracy: 0.9531 - val_loss: 3.5223 - val_accuracy: 0.5235\n",
      "Epoch 25/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0904 - accuracy: 0.9700 - val_loss: 9.9834 - val_accuracy: 0.2504\n",
      "Epoch 26/30\n",
      "176/176 [==============================] - 18s 103ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 6.6094 - val_accuracy: 0.4016\n",
      "Epoch 27/30\n",
      "176/176 [==============================] - 18s 104ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 2.3593 - val_accuracy: 0.6520\n",
      "Epoch 28/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 5.2093 - val_accuracy: 0.4221\n",
      "Epoch 29/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 10.3196 - val_accuracy: 0.2605\n",
      "Epoch 30/30\n",
      "176/176 [==============================] - 18s 102ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 8.9162 - val_accuracy: 0.3133\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit(\n",
    "    X_train, \n",
    "    tf.one_hot(y_train,10),\n",
    "    batch_size=128, \n",
    "    epochs=30,\n",
    "    validation_data=(X_test,tf.one_hot(y_test,10)),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f65063-b374-408b-88e1-162005830580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 2.4476 - val_accuracy: 0.5615\n",
      "Epoch 2/30\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.0406 - accuracy: 0.9861 - val_loss: 2.5073 - val_accuracy: 0.5884\n",
      "Epoch 3/30\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.0482 - accuracy: 0.9844 - val_loss: 3.8314 - val_accuracy: 0.4476\n",
      "Epoch 4/30\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 0.0502 - accuracy: 0.9826 - val_loss: 3.4743 - val_accuracy: 0.5265\n",
      "Epoch 5/30\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 5.0860 - val_accuracy: 0.3981\n",
      "Epoch 6/30\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.0381 - accuracy: 0.9867 - val_loss: 5.3347 - val_accuracy: 0.3653\n",
      "Epoch 7/30\n",
      "176/176 [==============================] - 22s 127ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 4.2507 - val_accuracy: 0.4829\n",
      "Epoch 8/30\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 0.0329 - accuracy: 0.9889 - val_loss: 2.5262 - val_accuracy: 0.6347\n",
      "Epoch 9/30\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 4.2422 - val_accuracy: 0.5597\n",
      "Epoch 10/30\n",
      "176/176 [==============================] - 22s 122ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 2.2768 - val_accuracy: 0.6209\n",
      "Epoch 11/30\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 2.4116 - val_accuracy: 0.5869\n",
      "Epoch 12/30\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.0822 - accuracy: 0.9754 - val_loss: 1.6143 - val_accuracy: 0.7041\n",
      "Epoch 13/30\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 2.2155 - val_accuracy: 0.6785\n",
      "Epoch 14/30\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 3.6104 - val_accuracy: 0.5724\n",
      "Epoch 15/30\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 2.9121 - val_accuracy: 0.6091\n",
      "Epoch 16/30\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 2.0339 - val_accuracy: 0.6653\n",
      "Epoch 17/30\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 3.7852 - val_accuracy: 0.5268\n",
      "Epoch 18/30\n",
      "176/176 [==============================] - 22s 126ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 9.1967 - val_accuracy: 0.2168\n",
      "Epoch 19/30\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 3.1495 - val_accuracy: 0.6013\n",
      "Epoch 20/30\n",
      "176/176 [==============================] - 21s 122ms/step - loss: 0.0256 - accuracy: 0.9908 - val_loss: 4.5406 - val_accuracy: 0.5951\n",
      "Epoch 21/30\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 2.6408 - val_accuracy: 0.5511\n",
      "Epoch 22/30\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 1.1335 - val_accuracy: 0.7844\n",
      "Epoch 23/30\n",
      "176/176 [==============================] - 22s 123ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 2.8569 - val_accuracy: 0.5687\n",
      "Epoch 24/30\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 2.6195 - val_accuracy: 0.6541\n",
      "Epoch 25/30\n",
      "176/176 [==============================] - 21s 121ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 2.2863 - val_accuracy: 0.7176\n",
      "Epoch 26/30\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.0428 - accuracy: 0.9859 - val_loss: 2.0709 - val_accuracy: 0.7383\n",
      "Epoch 27/30\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 1.5397 - val_accuracy: 0.7857\n",
      "Epoch 28/30\n",
      "176/176 [==============================] - 22s 125ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 2.8024 - val_accuracy: 0.6200\n",
      "Epoch 29/30\n",
      "176/176 [==============================] - 22s 124ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 2.9879 - val_accuracy: 0.6541\n",
      "Epoch 30/30\n",
      "176/176 [==============================] - 21s 120ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.9824 - val_accuracy: 0.8469\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit(\n",
    "    X_train, \n",
    "    tf.one_hot(y_train,10),\n",
    "    batch_size=128, \n",
    "    epochs=30,\n",
    "    validation_data=(X_test,tf.one_hot(y_test,10)),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f77a58e5-3390-41df-b531-ed50d5363986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65535"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()-X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b735ee9-1958-4680-98e5-7fbcc19bb20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 1148, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "522fa5e1-e53e-4749-b06f-5862ddba10fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3000.000000\n",
       "mean      3499.474667\n",
       "std       1181.144044\n",
       "min       1148.000000\n",
       "25%       2738.750000\n",
       "50%       3358.500000\n",
       "75%       4082.250000\n",
       "max      18262.000000\n",
       "Name: Size, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[\"Size\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe280b3b-be6e-4e2a-8ce2-34970b1fcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(model.history.history,open(\"results/AudioMNIST/BinaryNetSpectralOnly2.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e238354a-ef2a-4f1a-a6d5-1643e63c638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (None, 2000, 1)     0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  (None, 1, 1)        0           ['input_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 2000, 1)      0           ['gaussian_noise[0][0]',         \n",
      "                                                                  'tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2000, 1)     3           ['tf.math.truediv[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 2000, 128)    512         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 999, 128)     0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 999, 128)     147584      ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 999, 128)    0           ['conv1d_1[0][0]',               \n",
      " da)                                                              'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 499, 128)    0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 499, 128)    384         ['max_pooling1d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 499, 128)     311424      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 499, 128)    0           ['conv1d_2[0][0]',               \n",
      " mbda)                                                            'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 249, 128)    0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 31872)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 31872)       95616       ['flatten[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          8159488     ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 256)         768         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           2570        ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 10)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,718,349\n",
      "Trainable params: 8,653,835\n",
      "Non-trainable params: 64,514\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a690dd7f-7018-4733-ad77-8fead59b113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Size</th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george</td>\n",
       "      <td>8000</td>\n",
       "      <td>2384</td>\n",
       "      <td>0      -1489\n",
       "1       -962\n",
       "2       -606\n",
       "3      ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>george</td>\n",
       "      <td>8000</td>\n",
       "      <td>4727</td>\n",
       "      <td>0       36\n",
       "1       18\n",
       "2       63\n",
       "3       75\n",
       "4 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>george</td>\n",
       "      <td>8000</td>\n",
       "      <td>5958</td>\n",
       "      <td>0      -175\n",
       "1      -509\n",
       "2       293\n",
       "3       24...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>george</td>\n",
       "      <td>8000</td>\n",
       "      <td>3661</td>\n",
       "      <td>0       103\n",
       "1       138\n",
       "2       196\n",
       "3       17...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "      <td>8000</td>\n",
       "      <td>4050</td>\n",
       "      <td>0        67\n",
       "1        91\n",
       "2       104\n",
       "3       14...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>8000</td>\n",
       "      <td>2877</td>\n",
       "      <td>0       -3\n",
       "1      -13\n",
       "2        0\n",
       "3      -10\n",
       "4 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>8000</td>\n",
       "      <td>2778</td>\n",
       "      <td>0       -7\n",
       "1       10\n",
       "2       11\n",
       "3       12\n",
       "4 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>8000</td>\n",
       "      <td>2815</td>\n",
       "      <td>0        8\n",
       "1        3\n",
       "2        8\n",
       "3        2\n",
       "4 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>8000</td>\n",
       "      <td>3164</td>\n",
       "      <td>0       12\n",
       "1        4\n",
       "2       15\n",
       "3       10\n",
       "4 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>yweweler</td>\n",
       "      <td>8000</td>\n",
       "      <td>3507</td>\n",
       "      <td>0       -2\n",
       "1       -9\n",
       "2       -5\n",
       "3       -9\n",
       "4 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Person  Rate  Size                                               Data  \\\n",
       "0       george  8000  2384  0      -1489\n",
       "1       -962\n",
       "2       -606\n",
       "3      ...   \n",
       "1       george  8000  4727  0       36\n",
       "1       18\n",
       "2       63\n",
       "3       75\n",
       "4 ...   \n",
       "2       george  8000  5958  0      -175\n",
       "1      -509\n",
       "2       293\n",
       "3       24...   \n",
       "3       george  8000  3661  0       103\n",
       "1       138\n",
       "2       196\n",
       "3       17...   \n",
       "4       george  8000  4050  0        67\n",
       "1        91\n",
       "2       104\n",
       "3       14...   \n",
       "...        ...   ...   ...                                                ...   \n",
       "2995  yweweler  8000  2877  0       -3\n",
       "1      -13\n",
       "2        0\n",
       "3      -10\n",
       "4 ...   \n",
       "2996  yweweler  8000  2778  0       -7\n",
       "1       10\n",
       "2       11\n",
       "3       12\n",
       "4 ...   \n",
       "2997  yweweler  8000  2815  0        8\n",
       "1        3\n",
       "2        8\n",
       "3        2\n",
       "4 ...   \n",
       "2998  yweweler  8000  3164  0       12\n",
       "1        4\n",
       "2       15\n",
       "3       10\n",
       "4 ...   \n",
       "2999  yweweler  8000  3507  0       -2\n",
       "1       -9\n",
       "2       -5\n",
       "3       -9\n",
       "4 ...   \n",
       "\n",
       "      Label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2995      9  \n",
       "2996      9  \n",
       "2997      9  \n",
       "2998      9  \n",
       "2999      9  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "029d1861-9e4c-4255-80fd-9aa49db38d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 2000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " gaussian_noise_13 (GaussianNoi  (None, 2000, 1)     0           ['input_14[0][0]']               \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  (None, 1, 1)        0           ['input_14[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 2000, 1)      0           ['gaussian_noise_13[0][0]',      \n",
      "                                                                  'tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 2000, 1)     3           ['tf.math.truediv[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 2000, 128)    512         ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling1d_30 (MaxPooling1D  (None, 999, 128)    0           ['conv1d_30[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 999, 128)     147584      ['max_pooling1d_30[0][0]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 999, 128)    0           ['conv1d_31[0][0]',              \n",
      " ambda)                                                           'max_pooling1d_30[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_31 (MaxPooling1D  (None, 499, 128)    0           ['tf.__operators__.add_20[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 499, 128)    384         ['max_pooling1d_31[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 499, 128)     311424      ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 499, 128)    0           ['conv1d_32[0][0]',              \n",
      " ambda)                                                           'batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling1d_32 (MaxPooling1D  (None, 249, 128)    0           ['tf.__operators__.add_21[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 31872)        0           ['max_pooling1d_32[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 31872)       95616       ['flatten_9[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 256)          8159488     ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 256)         768         ['dense_18[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 10)           2570        ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 10)           0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,718,349\n",
      "Trainable params: 8,653,835\n",
      "Non-trainable params: 64,514\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "031097fe-b206-451f-a269-507ead66883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10354\n",
       "1        7605\n",
       "2        8221\n",
       "3        6404\n",
       "4        6165\n",
       "        ...  \n",
       "2995      820\n",
       "2996     1880\n",
       "2997      978\n",
       "2998      966\n",
       "2999      951\n",
       "Name: Data, Length: 3000, dtype: int16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[\"Data\"].map(lambda D:D.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f59c4ece-412a-485e-b3fe-3039dbf4acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=U.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c3b688e-a9d3-46c8-aeb8-99ace3526f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L[\"Mean\"]=U[\"Data\"].map(lambda D:D.mean())\n",
    "L[\"Max\"]=U[\"Data\"].map(lambda D:D.max())\n",
    "L[\"Min\"]=U[\"Data\"].map(lambda D:D.min())\n",
    "L[\"Std\"]=U[\"Data\"].map(lambda D:D.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a07de5a1-5463-449a-8ebd-0acf03e1f145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>Size</th>\n",
       "      <th>Label</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>george</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>3533.740</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.850576</td>\n",
       "      <td>9715.212</td>\n",
       "      <td>-10715.504</td>\n",
       "      <td>1986.108635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jackson</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>4131.680</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.062773</td>\n",
       "      <td>13397.494</td>\n",
       "      <td>-14633.924</td>\n",
       "      <td>2909.242220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lucas</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>4593.688</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.920933</td>\n",
       "      <td>10756.182</td>\n",
       "      <td>-16556.192</td>\n",
       "      <td>2039.574311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nicolas</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>2793.502</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-237.696940</td>\n",
       "      <td>5970.432</td>\n",
       "      <td>-8285.184</td>\n",
       "      <td>1588.342554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theo</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>3110.898</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.004797</td>\n",
       "      <td>1816.584</td>\n",
       "      <td>-1487.426</td>\n",
       "      <td>367.106162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yweweler</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>2833.340</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.411068</td>\n",
       "      <td>1585.138</td>\n",
       "      <td>-2448.024</td>\n",
       "      <td>398.944125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rate      Size  Label        Mean        Max        Min  \\\n",
       "Person                                                                \n",
       "george    8000.0  3533.740    4.5   -0.850576   9715.212 -10715.504   \n",
       "jackson   8000.0  4131.680    4.5   -0.062773  13397.494 -14633.924   \n",
       "lucas     8000.0  4593.688    4.5    0.920933  10756.182 -16556.192   \n",
       "nicolas   8000.0  2793.502    4.5 -237.696940   5970.432  -8285.184   \n",
       "theo      8000.0  3110.898    4.5   -0.004797   1816.584  -1487.426   \n",
       "yweweler  8000.0  2833.340    4.5   -0.411068   1585.138  -2448.024   \n",
       "\n",
       "                  Std  \n",
       "Person                 \n",
       "george    1986.108635  \n",
       "jackson   2909.242220  \n",
       "lucas     2039.574311  \n",
       "nicolas   1588.342554  \n",
       "theo       367.106162  \n",
       "yweweler   398.944125  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.groupby(\"Person\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3eaa14ff-c274-4ae7-8459-1af71520c65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 2000, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0263f10-c176-4039-852c-817c27f20103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3286408c-86eb-4b85-b2e9-70855e0564a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30000, 4000), dtype=float32, numpy=\n",
       "array([[-2352.      , -2022.      , -5387.      , ...,  -189.77325 ,\n",
       "          -39.983086,   264.06302 ],\n",
       "       [ 3530.      ,  3051.      ,  2195.      , ...,   200.67476 ,\n",
       "           95.373924,  -260.94455 ],\n",
       "       [-2318.      , -1776.      , -2747.      , ...,   363.40054 ,\n",
       "          388.05865 ,  -143.78802 ],\n",
       "       ...,\n",
       "       [ -344.      ,  -235.      ,   -95.      , ...,   302.15637 ,\n",
       "           32.97239 ,    63.057533],\n",
       "       [  128.      ,   113.      ,    95.      , ...,  -188.84828 ,\n",
       "         -389.05484 ,  -243.38365 ],\n",
       "       [   51.      ,    82.      ,    75.      , ...,  -301.0248  ,\n",
       "          -50.201347,   -66.22906 ]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "930f2247-53e9-4b42-9266-38bab369305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, ste_sign_18_layer_call_fn, ste_sign_18_layer_call_and_return_conditional_losses while saving (showing 5 of 39). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained/ABCNet-AudioMNIST/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained/ABCNet-AudioMNIST/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"trained/ABCNet-AudioMNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33ac4641-8c29-433b-9c8b-2edf4f3bef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+model_1 stats-----------------------------------------------------------------------------------------------+\n",
      "| Layer                   Input prec.          Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                               (bit)                        x 1       x 1     (kB)                          |\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "| input_4                           -    (-1, 2000, 1)         0         0        0           ?            ? |\n",
      "| gaussian_noise_3                  -    (-1, 2000, 1)         0         0        0           ?            ? |\n",
      "| tf.math.reduce_max_3              -       (-1, 1, 1)         0         0        0           ?            ? |\n",
      "| tf.math.truediv_3                 -    (-1, 2000, 1)         0         0        0           ?            ? |\n",
      "| batch_normalization_13            -    (-1, 2000, 1)         0         2     0.01           0            0 |\n",
      "| hola                              1  (-1, 2000, 128)       384       128     0.55      768000            0 |\n",
      "| max_pooling1d_9                   -   (-1, 999, 128)         0         0        0           0            0 |\n",
      "| quant_conv1d_6                    1   (-1, 999, 128)    147456       128    18.50   147308544            0 |\n",
      "| tf.__operators__.add_6            -   (-1, 999, 128)         0         0        0           ?            ? |\n",
      "| max_pooling1d_10                  -   (-1, 499, 128)         0         0        0           0            0 |\n",
      "| batch_normalization_15            -   (-1, 499, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv1d_7                    1   (-1, 499, 128)    311296       128    38.50   155336704            0 |\n",
      "| tf.__operators__.add_7            -   (-1, 499, 128)         0         0        0           ?            ? |\n",
      "| max_pooling1d_11                  -   (-1, 249, 128)         0         0        0           0            0 |\n",
      "| flatten_3                         -      (-1, 31872)         0         0        0           0            0 |\n",
      "| batch_normalization_16            -      (-1, 31872)         0     63744   249.00           0            0 |\n",
      "| abc_dense_1                       1         multiple  24477696       774  2991.02           0            0 |\n",
      "| batch_normalization_17            -        (-1, 256)         0       512     2.00           0            0 |\n",
      "| dense_1                           -         (-1, 10)         0      2570    10.04           0         2560 |\n",
      "| activation_1                      -         (-1, 10)         0         0        0           ?            ? |\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                 24936832     68242  3310.62   303413248         2560 |\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "+model_1 summary------------------------------+\n",
      "| Total params                      25 M      |\n",
      "| Trainable params                  24.9 M    |\n",
      "| Non-trainable params              64.5 k    |\n",
      "| Model size                        3.23 MiB  |\n",
      "| Model size (8-bit FP weights)     3.04 MiB  |\n",
      "| Float-32 Equivalent               95.39 MiB |\n",
      "| Compression Ratio of Memory       0.03      |\n",
      "| Number of MACs                    303 M     |\n",
      "| Ratio of MACs that are binarized  1.0000    |\n",
      "+---------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7034e25-60bf-4be7-982f-58121fe0913c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17808/2530791209.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a0ada8b-1711-4245-a138-20bf2c26b6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n",
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(shape=(3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2eee2c0-d1ab-4da0-804a-56f2f48352b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "44\n",
      "33\n",
      "44\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23114/3228746089.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mABCNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mABCDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mabc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_2_9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_2_9/lib/python3.9/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     raise TypeError('Keras symbolic inputs/outputs do not '\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0;34m'implement `__len__`. You may be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0;34m'trying to pass Keras symbolic inputs/outputs '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly."
     ]
    }
   ],
   "source": [
    "p=tf.keras.layers.Input(shape=(11,))\n",
    "q=ABCNet.ABCDense(10,**abc_kwargs)(p)\n",
    "M=tf.keras.Model(p,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcb87b-a98e-418f-b08d-743df33c30dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
